<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en"><generator uri="https://jekyllrb.com/" version="4.3.4">Jekyll</generator><link href="https://nayoung10.github.io/feed.xml" rel="self" type="application/atom+xml"/><link href="https://nayoung10.github.io/" rel="alternate" type="text/html" hreflang="en"/><updated>2025-06-01T15:56:31+00:00</updated><id>https://nayoung10.github.io/feed.xml</id><title type="html">blank</title><subtitle>A simple, whitespace theme for academics. Based on [*folio](https://github.com/bogoli/-folio) design. </subtitle><entry><title type="html">[AI810 Blog Post (20255036)] Generative Models for Crystals: Inorganic Crystals &amp;amp; Metal-Orgranic Frameworks</title><link href="https://nayoung10.github.io/blog/2025/distill/" rel="alternate" type="text/html" title="[AI810 Blog Post (20255036)] Generative Models for Crystals: Inorganic Crystals &amp;amp; Metal-Orgranic Frameworks"/><published>2025-06-01T00:00:00+00:00</published><updated>2025-06-01T00:00:00+00:00</updated><id>https://nayoung10.github.io/blog/2025/distill</id><content type="html" xml:base="https://nayoung10.github.io/blog/2025/distill/"><![CDATA[ <div class="preamble"> $$ \newcommand{\cM}{\mathcal{M}} \newcommand{\cA}{\mathcal{A}} \newcommand{\bA}{\mathbf{A}} \newcommand{\bX}{\mathbf{X}} \newcommand{\bL}{\mathbf{L}} \newcommand{\bS}{\mathbf{S}} \newcommand{\bbR}{\mathbb{R}} $$ </div> <h2 id="motivation">Motivation</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/examples-480.webp 480w,/assets/img/2025-04-28-_nayoung/examples-800.webp 800w,/assets/img/2025-04-28-_nayoung/examples-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/examples.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Figure 1. Examples of crystals.</figcaption> </figure> <p>Materials span a wide range of structural and chemical complexities, from amorphous polymers to highly ordered solids. Among them, <strong>crystals</strong> refer to materials with a <em>regular</em>, <em>repeating</em> arrangement of atoms or molecules. Many everyday materials are crystalline (Figure 1): <em>diamond</em>, known for its extreme hardness; <em>quartz</em>, used in electronics; and <em>table salt</em>, essential in daily life. Designing new crystalline materials with desirable properties is at the heart of breakthroughs in energy, electronics, and environmental sustainability.</p> <p>In recent years, <strong>generative models</strong> have gained attention as powerful tools for automating the design of novel crystal structures. Most existing work focuses on <strong>inorganic crystals</strong><d-cite key="jiao2024crystal"></d-cite><d-cite key="millerflowmm"></d-cite><d-cite key="linequivariant"></d-cite>, which include materials like semiconductors, superconductors, and catalysts. More recently, some attention has turned to <strong>metal-organic frameworks (MOFs)</strong><d-cite key="fu2023mofdiff"></d-cite>, a crystalline materials composed of <strong>metal clusters</strong> and <strong>organic linkers</strong>. Their porous structures and high tunability make them promising candidates for gas storage<d-cite key="li2018recent"></d-cite><d-cite key="qian2020mof"></d-cite>, catalysis,<d-cite key="lee2009metal"></d-cite> and drug delivery<d-cite key="horcajada2012metal"></d-cite>.</p> <h3 id="two-types-of-crystals-two-types-of-challenges">Two Types of Crystals, Two Types of Challenges</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/inorganic_vs_mof-480.webp 480w,/assets/img/2025-04-28-_nayoung/inorganic_vs_mof-800.webp 800w,/assets/img/2025-04-28-_nayoung/inorganic_vs_mof-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/inorganic_vs_mof.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Examples of inorganic crystals and metal-organic frameworks.</figcaption> </figure> <p>While both inorganic crystals and MOFs are crystalline materials, their fundamental differences introduce distinct challenges for generative modeling:</p> <ul> <li><strong>Inorganic crystals</strong> typically contain fewer atoms per structure and exhibit high degrees of <strong>symmetry</strong>. However, they lack natural subunits, making them difficult to decompose or simplify for modeling.</li> <li><strong>MOFs</strong>, in contrast, often consist of hundreds to thousands of atoms per structure. Fortunately, their <strong>modular nature</strong> allows them to be decomposed into well-defined building blocks: metal nodes and organic linkers.</li> </ul> <table> <thead> <tr> <th> </th> <th><strong>Inorganic</strong></th> <th><strong>MOF</strong></th> </tr> </thead> <tbody> <tr> <td>Size</td> <td>~10-50 atoms/structure</td> <td>~50-2000 atoms/structure</td> </tr> <tr> <td>Key structural trait</td> <td>Symmetry-rich</td> <td>Modular</td> </tr> <tr> <td>Generation challenge</td> <td>Capturing symmetry</td> <td>Scaling to large structures</td> </tr> </tbody> </table> <p>In this blogpost, we explore two recent generative models that address these distinct challenges:</p> <ul> <li><strong>SymmCD (ICLR 2025)</strong><d-cite key="levy2025symmcd"></d-cite> targets <em>inorganic crystals</em> using a diffusion model that explicitly incorporates <em>symmetry</em>. By learning to generate only the <em>asymmetric unit</em> and expanding it via symmetry operations, it ensures validity and efficiency in generation.</li> <li><strong>MOFDiff (ICLR 2024)</strong><d-cite key="fu2023mofdiff"></d-cite> focuses on <em>MOFs</em> by leveraging their modularity through a <em>coarse-grained representation</em>. By learning to generate the coarse-grained representation, MOFDiff succesffully generates large and complex MOF structures.</li> </ul> <p>The following table provides a quick <strong>summary</strong> of the two works:</p> <table> <thead> <tr> <th> </th> <th><strong>SymmCD</strong></th> <th><strong>MOFDiff</strong></th> </tr> </thead> <tbody> <tr> <td>Target material</td> <td>Inorganic crystals</td> <td>Metal-organic frameworks</td> </tr> <tr> <td>Dataset</td> <td>Materials Project<d-cite key="Jain2013"></d-cite></td> <td>BW-DB<d-cite key="boyd2019data"></d-cite></td> </tr> <tr> <td>Key idea</td> <td>Generate asymmetric unit and reconstruct full structure using symmetry</td> <td>Generate coarse-grained MOF structure based the modular nature of MOFs</td> </tr> <tr> <td>Method</td> <td>Diffusion</td> <td>Diffusion</td> </tr> <tr> <td>Publication</td> <td>ICLR 2025</td> <td>ICLR 2024</td> </tr> </tbody> </table> <h2 id="symmcd-symmetry-preserving-crystal-generation-with-diffusion-models">SymmCD: Symmetry-Preserving Crystal Generation with Diffusion Models</h2> <h3 id="preliminary-representing-crystals">Preliminary: Representing Crystals</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/unit_cell-480.webp 480w,/assets/img/2025-04-28-_nayoung/unit_cell-800.webp 800w,/assets/img/2025-04-28-_nayoung/unit_cell-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/unit_cell.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Figure 2. The unit cell representation of a crystal. The ideal, infinite crystal structure can be recovered by replicating the cell along the three lattice vectors.</figcaption> </figure> <p>To represent a 3D structure of a <strong>molecule</strong> with \(N\) atoms, we typically specify two components:</p> <ol> <li>The atom types \(\bA=(a_1, \dots, a_N) \in \cA^N\), where each \(\cA\) is the set of possible elements,</li> <li>The 3D coordinates of those atoms, \(\bX=(x_1, \dots, x_N) \in \bbR^{N \times 3}\).</li> </ol> <p><strong>Crystals</strong> are similar, but with one key addition: the <strong>lattice</strong>. The lattice is defined by three lattice vectors \(\mathbf{L}=(l_1, l_2, l_3) \in \bbR^{N \times 3}\) which describe how the unit cell repeasts in space. This compact <strong>unit cell representation</strong> \(\cM = (\bA, \bX, \bL)\) contains all the information needed to define a crystal. By translating the atoms along the lattice vectors \(l_1, l_2, l_3\), we can reconstruct the full (theorectically infinite) periodic structure of the crystal (Figure 2).</p> <h3 id="asymmetric-unit-and-site-symmetries">Asymmetric Unit and Site Symmetries</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/asymmetric_unit-480.webp 480w,/assets/img/2025-04-28-_nayoung/asymmetric_unit-800.webp 800w,/assets/img/2025-04-28-_nayoung/asymmetric_unit-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/asymmetric_unit.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Figure 3. (left) An asymmetric unit can be unfolded using symmetry operations to reconstruct the full unit cell. (right) SymmCD generates the asymmetric unit, which contains the atom types, coordinates, lattice, and site symmetries.</figcaption> </figure> <p>While the unit cell representation \(\cM = (\bA, \bX, \bL)\) compactly represents a crystal, <strong>SymmCD</strong> uses an even smaller representation: the <strong>asymmetric unit</strong>. The asymmetric unit can be combined with crystal symmetry operations to reconstruct the full unit cell (Figure 3, <em>left</em>).</p> <p>A useful analogy for understanding the asymmetric unit is <em>cutting a paper snowflake</em><d-cite key="fredericks2021pyxtal"></d-cite>: the folded paper represents the asymmetrc unit, and unfolding aplies the symmetry to create the full pattern of the paper snowflake.</p> <p>But here’s the subtle part: <em>where</em> you make the cut affects how many times it appears in the final pattern. For instance, a cut at the center of the folded paper is repeated six times, while a cut at an edge appears three times. In crystallography, this concept is captured by the <strong>site symmetry</strong> – it tells you <em>how</em> to replicate an atom based on its position on the asymmetric unit.</p> <p>SymmCD leverages these two simple concepts for inorganic crystal generation. Rather than generating the full crystal, it generates just the asymmetric unit, which contains the atom types, coordinates, lattice, and site symmetries (Figure 3, <em>right</em>). This simplifies the generation process while guaranteeing that the resulting structures are symmetric.</p> <p>Mathematically, we represent an asymmetric unit with:</p> <ul> <li>Atom types \(\bA' = (a_1, \dots, a_M) \in \cA^M\),</li> <li>3D coordinates \(\bX=(x_1, \dots, x_M) \in \bbR^{M \times 3}\),</li> <li>Asymmetric lattice \(\mathbf{k} \in \mathbb{R}^6\) (see the paper<d-cite key="levy2025symmcd"></d-cite> for details), and</li> <li>Site symmetries \(\bS = (S_{x_1'}, \dots, S_{x_M'}) \in \mathcal{P}^M\), where \(\mathcal{P}\) denotes the set of all possible site symmetries.</li> </ul> <p>Note that \(M \leq N\), since the asymmetric unit contains only a subset of the atoms in the full unit cell.</p> <h3 id="symmcd-pre-processing-training-and-sampling">SymmCD: Pre-processing, Training, and Sampling</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/symmcd_pipeline-480.webp 480w,/assets/img/2025-04-28-_nayoung/symmcd_pipeline-800.webp 800w,/assets/img/2025-04-28-_nayoung/symmcd_pipeline-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/symmcd_pipeline.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Figure 4. The full pipeline of SymmCD, including pre-processing, training, sampling, and post-processing.</figcaption> </figure> <h4 id="pre-processing-extracting-the-asymmetric-unit">Pre-processing: Extracting the Asymmetric Unit</h4> <p>Recall that the core idea of SymmCD is to model the <strong>asymmetric unit</strong> rather than the entire unit cell. But <em>how</em> do we extract the asymmetric unit from a given crystal?</p> <p>Crucially, <em>all</em> crystals belong to one of just 230 space groups, each defining a unique set of symmetry operations. Given a crystal in unit cell form, \(\cM = (\bA, \bX, \bL)\), we first determine its space group \(G\) – this can be done using tools such as spglib<d-cite key="spglib"></d-cite>. The space group encodes the symmetries present in the crystal, which in turn define its asymmetric unit.</p> <p>Using this information, we convert the dataset from unit cell representation to asymmetric unit cell representation as follows: \(\begin{equation} \mathcal{D} = \{ (\bA, \bX, \bL) \} \Rightarrow{} \mathcal{D} = \{ (G, \mathbf{k}, \bA', \bX', \bS) \}. \end{equation}\)</p> <h4 id="training-the-model">Training the Model</h4> <p>SymmCD models the joint distribution over asymmetric unit components and the space group as: \(\begin{equation} p_{\theta}(G, \mathbf{k}, \bA', \bX', \bS)=p_{\theta}(\mathbf{k}, \bA', \bX', \bS \vert G)p(G). \end{equation}\)</p> <p>That is, once a space group \(G\) is specified (or sampled), the model generates a compatible asymmetric unit \((\mathbf{k}, \bA', \bX', \bS)\). To achieve this, SymmCD trains an E(3)-equivariant graph neural network (GNN), where the atom types and site symmetries \(\bA', \bS\) are learned with discrete diffusion and the lattice \(k, \bX'\) are learned with continuous diffusion.</p> <h4 id="sampling-and-post-processing">Sampling and Post-processing</h4> <p>Generating inorganic crystal structures with SymmCD involves three main steps:</p> <ol> <li>Select a space group \(G\) – either randomly or based on desired properties.</li> <li>Sample asymmetric unit \((\mathbf{k}, \bA', \bX', \bS)\) using the trained diffusion model.</li> <li>Project the generated atoms into valid <strong>Wyckoff positions</strong> based on their site symmetries.</li> </ol> <p>Why is this projection step necessary? Recall the paper snowflake analogy: a cut made at the center is repeated more times than one near the edge. In crystals, certain regions of the asymmetric unit permit only specific site symmetries. If a generated atom-site symmetry pair is invalid, its position must be projected a location compatible with the symmetry constraints.</p> <p>Finally, the full unit cell \(\cM = (\bA, \bX, \bL)\) is reconstructed by applying the symmetry operations associated with each atom’s site symmetry. By generating only the asymmetric unit, SymmCD reduces computational complexity while ensuring symmetric outputs.</p> <h3 id="experimental-results-symmcd-generates-diverse-and-novel-crystals">Experimental Results: SymmCD Generates Diverse and Novel Crystals</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/symmcd_results-480.webp 480w,/assets/img/2025-04-28-_nayoung/symmcd_results-800.webp 800w,/assets/img/2025-04-28-_nayoung/symmcd_results-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/symmcd_results.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Figure 5. Comparison of crystals generated by SymmCD and baseline models. (Left) Distribution of space group symmetries across generated samples. (Middle) Number of novel (unseen) structures produced by each model. (Right) Example crystal generated by SymmCD with space group Pmmm.</figcaption> </figure> <p>In the experiments, 10,000 crystals are generated from each model and evaluated based on the distribution of <strong>space group symmetries</strong> and <strong>novelty</strong>.</p> <p>Both SymmCD and DiffCSP++<d-cite key="jiaospace"></d-cite> generate crystals spanning a wide range of space group symmetries, demonstrating their capacity to model diverse crystal types (Figure 5, <em>left</em>). However, SymmCD achieves higher novelty, since it learns to generate asymmetric units from scratch, whereas DiffCSP++ relies on refining known templates (Figure 5, <em>middle</em>). Figure 5, <em>right</em> shows an example crystal generated by SymmCD with space group Pmmm, demonstrating the model’s ability produce valid and symmetric structures.</p> <h2 id="mofdiff-coarse-grained-diffusion-for-metal-organic-framework-design">MOFDiff: Coarse-grained Diffusion for Metal-Organic Framework Design</h2> <h3 id="preliminary-coarse-grained-representation-for-mofs">Preliminary: Coarse-grained Representation for MOFs</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/mof_representation-480.webp 480w,/assets/img/2025-04-28-_nayoung/mof_representation-800.webp 800w,/assets/img/2025-04-28-_nayoung/mof_representation-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/mof_representation.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Figure 6. Decomposing a MOF into its building blocks. (a) An example MOF unit cell. (b) Metal node and organic linkers visualized one at a time for visual clarity. (c) All four building blocks in the example. The blue dumbbell-shaped building block is metal, while others are organic.</figcaption> </figure> <p>Metal–Organic Frameworks (MOFs) are one of the structurally complex materials known. Compared to inorganic crystals, they are much larger, often containing hundreds to thousands of atoms per unit cell. This scale makes atom-level generative modeling both inefficient and prone to poor performance.</p> <p>Fortunately, MOFs come with a built-in advantage: <strong>modularity</strong>. Each MOF is composed of building blocks called metal clusters and organic linkers. Therefore, instead of representing MOFs as full atomic structures \((\bA, \bX, \bL)\), MOFDiff uses a simplified, coarse-grained representation \(\begin{equation} \cM^C = (\bA^C, \bX^C, \bL) \end{equation}\) where:</p> <ul> <li>\(\bA^C = (a_1^C, \dots, a_K^C) \in \mathbb{B}^{K}\) are the building block types (e.g., a metal node or linker),</li> <li>\(\bX^C = (x_1^C, \dots x_k^C) \in \bbR^{K \times 3}\) are their 3D Cartesian coordinates, and</li> <li>\(\bL\) is the lattice that defines periodicity (same as unit cell representation).</li> </ul> <p>The core idea behind MOFDiff is to learn this coarse-grained representation instead of modeling the full atomic structure. Since \(K \ll N\), this representation is much more efficient to model.</p> <h3 id="learning-building-block-representations">Learning Building Block Representations</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/contrastive_learning-480.webp 480w,/assets/img/2025-04-28-_nayoung/contrastive_learning-800.webp 800w,/assets/img/2025-04-28-_nayoung/contrastive_learning-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/contrastive_learning.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Figure 7. Schematic for learning building block representations. A contrastive loss is used to train the graph neural network encoder so that topologically same building blocks are mapped to nearby points in the embedding space.</figcaption> </figure> <p>How do we represent these building blocks effectively?</p> <p>A naive approach might be to extract all building blocks from the training dataset, assign each a one-hot encoding, then train a diffusion model: discrete diffusion for the building block types \(\bA^C\), and continuous diffusions for their positions \(\bX^C\) and lattice \(\bL\).</p> <p>However, the training dataset contains around 2 million of building blocks, which makes one-hot encoding extremely sparse and hard to learn. Also, many of these building blocks are topologically identical – they have the same atom and bond structure (i.e., same 2D graph), differing only slightly in 3D geometry, making this representation very inefficient.</p> <p>To overcome this, MOFDiff learns a <strong>dense</strong>, <strong>continuous</strong> embedding \(\bA^C\) for each building block that captures topological similarity. It does this by training a <strong>SE(3)-invariant graph neural network</strong> takes as input the \(i\) building block (i.e., its atom types and coordinates) and outputs a dense embedding \(\mathbf{b}_i \in \bbR^d\) corresponding to that building block.</p> <p>To ensure that the learned embeddings group similar building blocks together, MOFDiff uses a <strong>contrastive learning objective</strong> (Figure 7). Specifically, it first computes ECFP4, a molecular fingerprint which encodes topological information, then trains the models with a contrastive loss that brings structures with same ECFP4 close together in the embedding space.</p> <p>The contrastive loss is defined as: \(\begin{equation} \mathcal{L}_C = - \log \sum_{i \in \mathbf{B}} \left( \frac{\sum_{j \in \mathbf{B}_i^{+}} \exp(s_{i,j} / \tau)}{\sum_{j \in \mathbf{B} \setminus \{i\}} \exp(s_{i,j} / \tau)} \right) \end{equation}\) where</p> <ul> <li>$\mathbf{B}$ is a batch of building blocks,</li> <li>$\mathbf{B}_i^{+} \subseteq \mathbf{B}$ are building blocks with the same ECFP4 fingerprint as $i$,</li> <li>$s_{i,j}$ is the <em>cosine similarity</em> between projected building block embeddings:<br/> \(\begin{equation} s_{i,j} = \frac{\mathbf{p}_i^{\top} \mathbf{p}_j}{\|\mathbf{p}_i\| \|\mathbf{p}_j\|}, \quad \mathbf{p}_i = \operatorname{MLP}(\mathbf{b}_i) \end{equation}\)</li> <li>$\tau$ is the temperature.</li> </ul> <p>Once trained, this encoder maps each building block to a dense vector embedding. All MOFs in the dataset can then be transformed into their coarse-grained representation \(\cM = (\bA^C, \bX^C, \bL)\), where \(\bA^C = (\mathbf{b}_1, \dots, \mathbf{b}_K) \in \bbR^{K \times d}\) is the dense embedding. The paper uses \(d=32\), which is much more compact representation than a one-hot encoding over ~2M types of building blocks.</p> <h3 id="training-mofdiff">Training MOFDiff</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/mofdiff_training-480.webp 480w,/assets/img/2025-04-28-_nayoung/mofdiff_training-800.webp 800w,/assets/img/2025-04-28-_nayoung/mofdiff_training-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/mofdiff_training.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Figure 8. Schematic for training MOFDiff. There are three models involved: (1) an MLP model than predicts lattice L and number of building blocks K from latent vector z, (2) a denoising model over the coarse-grained structure, and (3) an encoder than encodes the coarse-grained representation into a latent vector z.</figcaption> </figure> <p>With the coarse-grained representation in place, it’s time to train the generative model.</p> <p>MOFDiff aims to model the full joint distribution over the coarse-grained structure and an additional latent variable \(\mathbf{z}\): \(\begin{equation} p_{\theta}(\bA^C, \bX^C, \bL, K, z) = p_{\theta}(\bL, K \vert \mathbf{z}) p_{\theta}(\bA^C, \bX^C \vert \bL, k, \mathbf{z}), \end{equation}\) where:</p> <ul> <li>\(\bA^C=(\mathbf{b}_1, \dots, \mathbf{b}_K) \in \bbR^{K \times d}\) and \(\bX^C = (x_1^C, \dots x_K^C) \in \bbR^{K \times 3}\) are the building block types and positions,</li> <li>\(\bL\) is the lattice,</li> <li>\(\mathbf{z}\) is a latent vector used for generating the \(\bL\), \(K\).</li> </ul> <p>MOFDiff factorizes this distribution as: \(\begin{equation} p_{\theta}(\bA^C, \bX^C, \bL, K, z) = p_{\theta}(\bL, K \vert \mathbf{z}) p_{\theta}(\bA^c, \bX^C \vert \bL, K, \mathbf{z}). \end{equation}\)</p> <p>The first part, \(p_{\theta}(L, K \vert \mathbf{z})\) is modeled using an MLP: \(\begin{equation} \hat{\bL}, \hat{K} = \operatorname{MLP}_{\bL, K}(\mathbf{z}), \end{equation}\) while the second part, \(p_{\theta}(\bA^c, \bX^C \vert L, K, \mathbf{z})\) is modeled using score-based diffusion, where a periodic graph neural network denoiser \(\operatorname{PGNN}_D\) predicts the noise in the atom types and coordinates as: \(\begin{equation} \mathbf{s}_{\bA^C}, \mathbf{s}_{\bX^C} = \operatorname{PGNN}_D(\tilde{\cM}_t^C, z). \end{equation}\) Here, \(\tilde{\cM}_t^C=(\bA_t^C, \bX_t^C, \bL)\) is the noised version of the coarse-grained structure at timestep \(t\) and \(\mathbf{z}\) is the latent vector produced with a periodic graph neural network encoder \(\operatorname{PGNN}_E\): $$ \begin{equation} \mathbf{z} = \operatorname{PGNN}_E(\cM^C). \end{equation}</p> <h4 id="objective-function">Objective function</h4> <p>The denoiser \(\operatorname{PGNN}_D(\cM_t^C, z)\) is trained using the standard denoising score objective: \(\begin{equation} \mathcal{L}_{\boldsymbol{A}}=\mathbb{E}_{t, \boldsymbol{M}^C, \boldsymbol{\epsilon}_{\boldsymbol{A}}}\left[\left\|\boldsymbol{\epsilon}_{\boldsymbol{A}}-\boldsymbol{s}_{\boldsymbol{A}_t^C, \boldsymbol{z}}\right\|^2\right], \quad \mathcal{L}_{\boldsymbol{X}}=\mathbb{E}_{t, \boldsymbol{M}^C, \boldsymbol{\epsilon}_{\boldsymbol{X}}}\left[\sigma_t^2\left\|\boldsymbol{\epsilon}_{\boldsymbol{X}}-\boldsymbol{s}_{\boldsymbol{X}_t^C, \boldsymbol{z}}\right\|^2\right]. \end{equation}\) \(\operatorname{MLP}_{\bL, K}(\mathbf{z})\) is supervised with the mean squared error and cross-entropy loss: \(\begin{equation} \mathcal{L}_{\boldsymbol{L}, K}=\|\boldsymbol{L}-\hat{\boldsymbol{L}}\|^2+\operatorname{CrossEntropy}(K, \hat{K}). \end{equation}\) Finally, the encoder \(\operatorname{PGNN}_E\) is regularized with a KL divergence \(\mathcal{L}_{\mathrm{KL}}\) to match a standard normal prior.</p> <p>The overall training objective for MOFDiff combines all components as: \(\begin{equation} \mathcal{L}_{\text {MOFDiff }}=\mathcal{L}_{\boldsymbol{A}}+\mathcal{L}_{\boldsymbol{X}}+\mathcal{L}_{\boldsymbol{L}, K}+\beta_{\mathrm{KL}} \mathcal{L}_{\mathrm{KL}}. \end{equation}\) where \(\beta_{\mathrm{KL}}\) is a hyperparameter that controls the strength of KL regularization, set to 0.01.</p> <h3 id="sampling-pipeline-for-mofdiff">Sampling Pipeline for MOFDiff</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/mofdiff_sampling-480.webp 480w,/assets/img/2025-04-28-_nayoung/mofdiff_sampling-800.webp 800w,/assets/img/2025-04-28-_nayoung/mofdiff_sampling-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/mofdiff_sampling.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Figure 9. Post-processing pipeline for MOFDiff. Once we sample a coarse-grained structure, we should (1) decode the building block identities, (2) rotate the building blocks with a self-assembly process, and (2) relax structure with UFF force field.</figcaption> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/self_assembly-480.webp 480w,/assets/img/2025-04-28-_nayoung/self_assembly-800.webp 800w,/assets/img/2025-04-28-_nayoung/self_assembly-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/self_assembly.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Figure 10. The illustration of self-assembly process. The self-assembly processes maximizes the connection between building blocks (connection points are shown in light blue).</figcaption> </figure> <p>Once MOFDiff is trained, we can generate a new MOF structure with the following process:</p> <ol> <li><strong>Sample</strong> a random latent code \(\mathbf{z} \sim \mathcal{N}(0,I)\).</li> <li><strong>Predict</strong> the lattice and number of building blocks: \(\begin{equation} \hat{\bL}, \hat{K} = \operatorname{MLP}_{\bL, K}(\mathbf{z}) \end{equation}\)</li> <li><strong>Run denoising diffusion</strong> with the trained denoiser \(\operatorname{PGNN}_D(\tilde{\cM}_t^C, z)\) to generate the coarse-grained structure \((\bA^C, \bX^C, \bL)\).</li> </ol> <p>At this point, we have a <strong>coarse-grained MOF</strong>. We now need to recover the full atomic structure with fine-grained details. Here’s how (Figure 9):</p> <ol> <li><strong>Building block decoding</strong>. For each generated embedding \(\bA^C\), we find the building block from the training dataset that has the closest embedding with nearest neighbor search. We then retrieve actual atom types and coordinates of this closest building block.</li> <li><strong>Self-assembly process</strong>. Since we have only predicted the center of mass of each building block with \(\bX^C\), we now need to know <em>how to rotate them</em>. MOFDiff uses an optimization-based <strong>sef-assembly algorithm</strong> to find the rotation that maximizes the alignment of connection points between the building blocks (Figure 10).</li> <li><strong>Force field relaxation</strong>. Finally, the assembled structure undergoes relaxation with energy minimization with the UFF force field. This step ensures that we can make a fine-grained refinement to get the final structure.</li> </ol> <h3 id="evaluation-results-mofdiff-generates-high-quality-mofs">Evaluation Results: MOFDiff generates high-quality MOFs</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/mofdiff_results-480.webp 480w,/assets/img/2025-04-28-_nayoung/mofdiff_results-800.webp 800w,/assets/img/2025-04-28-_nayoung/mofdiff_results-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/mofdiff_results.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Figure 11. Results for MOFDiff. (left) Validity, novelty, and uniqueness (VNU) of generated structures. (middle) CO2 working capacity distribution of MOFDiff and the training dataset. (right) Promising MOFs with high CO2 capacity sampled with MOFDiff.</figcaption> </figure> <h4 id="generating-valid-novel-and-unique-mofs">Generating Valid, Novel, and Unique MOFs</h4> <p>How does MOFDiff perform in practice? To evaluate it, the authors sampled 10,000 MOF structures and assessed them on three key metrics: <strong>validity</strong>, <strong>novelty</strong>, and <strong>uniqueness</strong>.</p> <ul> <li><strong>Validity</strong>: A structure is considered valid if it passes the validity check with <code class="language-plaintext highlighter-rouge">MOFchecker</code><d-cite key="xin2025mofchecker"></d-cite>, which assesses whether a MOF is chemically and physically valid based on a set of criteria including the presence of at least one metal, carbon, and hydrogen atom; overlapping atoms; and valency.</li> <li><strong>Novelty</strong>: A structure is novel if it does not exist in the training dataset. This is measured with <code class="language-plaintext highlighter-rouge">MOFid</code><d-cite key="bucior2019identification"></d-cite>, which computes a unique identifier for a MOF based on its building blocks and connectivity.</li> <li><strong>Uniqueness</strong>: We find the unique structures by filtering out the duplicates from the generated set of structures.</li> </ul> <p>Out of 10,000 generated structures, <strong>3,012 passed the validity check</strong> and <strong>2,998</strong> were <strong>valid</strong>, <strong>novely</strong>, and <strong>unique</strong> (Figure 11, <em>left</em>). That’s nearly 3,000 high-quality MOFs generated from scratch – an impressive result given the structural complexity and the size of MOFs.</p> <h4 id="discovering-high-performing-mofs-for-carbon-capture">Discovering High-performing MOFs for Carbon Capture</h4> <p>Thanks to the latent variable \(\mathbf{z}\), MOFDiff can also be used for property-guided generation.</p> <p>Suppose you want to discover MOFs with high CO2 working capacity – a key metric for carbon capture technology. MOFDiff enables this by learning a simple property predictor \(\begin{equation} \hat{\mathbf{c}} = \operatorname{MLP}_P(\mathbf{z}), \end{equation}\) where \(\mathbf{c}\) is the property of interest (e.g., CO2 capacity). This predictor is trained with the mean squared error loss using known property labels.</p> <p>To sample MOFs with desired properties, we can let MOFDiff generate many latent vectors \(\mathbf{z} \sim \mathcal{N}(0, I)\), compute the CO2 working capacity \(\hat{\mathbf{c}}\) with the trained predictor, and only decode \(\mathbf{z}\)’s with high CO2 working capacity.</p> <p>In experiments, this approach successfully generates MOFs with higher CO2 working capcity than those in the training dataset, demonstrating MOFDiff’s potential for targeted material discovery (Figure 10, <em>middle</em>). We also show some examples of promising candidates generated by MOFDiff in Figure 10, <em>right</em>.</p>]]></content><author><name>Nayoung Kim</name></author><summary type="html"><![CDATA[In this work, we review to recent works on materials generation. One is SymmCD, which generates inorganic crystals by exploiting the special symmetry property of crystals called 'space groups'. The other is MOFDiff, a coarse-grained diffusion model that generates metal-organic frameworks (MOFs) by exploiting the modular nature of MOFs.]]></summary></entry><entry><title type="html">[AI810 Blog Post (20255036)] Generative Models for Crystals: Inorganic Crystals &amp;amp; Metal-Orgranic Frameworks</title><link href="https://nayoung10.github.io/blog/2025/_nayoung/" rel="alternate" type="text/html" title="[AI810 Blog Post (20255036)] Generative Models for Crystals: Inorganic Crystals &amp;amp; Metal-Orgranic Frameworks"/><published>2025-06-01T00:00:00+00:00</published><updated>2025-06-01T00:00:00+00:00</updated><id>https://nayoung10.github.io/blog/2025/_nayoung</id><content type="html" xml:base="https://nayoung10.github.io/blog/2025/_nayoung/"><![CDATA[ <div class="preamble"> $$ \newcommand{\cM}{\mathcal{M}} \newcommand{\cA}{\mathcal{A}} \newcommand{\bA}{\mathbf{A}} \newcommand{\bX}{\mathbf{X}} \newcommand{\bL}{\mathbf{L}} \newcommand{\bS}{\mathbf{S}} \newcommand{\bbR}{\mathbb{R}} $$ </div> <h2 id="motivation">Motivation</h2> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/examples-480.webp 480w,/assets/img/2025-04-28-_nayoung/examples-800.webp 800w,/assets/img/2025-04-28-_nayoung/examples-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/examples.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Figure 1. Examples of crystals.</figcaption> </figure> <p>Materials span a wide range of structural and chemical complexities, from amorphous polymers to highly ordered solids. Among them, <strong>crystals</strong> refer to materials with a <em>regular</em>, <em>repeating</em> arrangement of atoms or molecules. Many everyday materials are crystalline (Figure 1): <em>diamond</em>, known for its extreme hardness; <em>quartz</em>, used in electronics; and <em>table salt</em>, essential in daily life. Designing new crystalline materials with desirable properties is at the heart of breakthroughs in energy, electronics, and environmental sustainability.</p> <p>In recent years, <strong>generative models</strong> have gained attention as powerful tools for automating the design of novel crystal structures. Most existing work focuses on <strong>inorganic crystals</strong><d-cite key="jiao2024crystal"></d-cite><d-cite key="millerflowmm"></d-cite><d-cite key="linequivariant"></d-cite>, which include materials like semiconductors, superconductors, and catalysts. More recently, some attention has turned to <strong>metal-organic frameworks (MOFs)</strong><d-cite key="fu2023mofdiff"></d-cite>, a crystalline materials composed of <strong>metal clusters</strong> and <strong>organic linkers</strong>. Their porous structures and high tunability make them promising candidates for gas storage<d-cite key="li2018recent"></d-cite><d-cite key="qian2020mof"></d-cite>, catalysis,<d-cite key="lee2009metal"></d-cite> and drug delivery<d-cite key="horcajada2012metal"></d-cite>.</p> <h3 id="two-types-of-crystals-two-types-of-challenges">Two Types of Crystals, Two Types of Challenges</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/inorganic_vs_mof-480.webp 480w,/assets/img/2025-04-28-_nayoung/inorganic_vs_mof-800.webp 800w,/assets/img/2025-04-28-_nayoung/inorganic_vs_mof-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/inorganic_vs_mof.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Examples of inorganic crystals and metal-organic frameworks.</figcaption> </figure> <p>While both inorganic crystals and MOFs are crystalline materials, their fundamental differences introduce distinct challenges for generative modeling:</p> <ul> <li><strong>Inorganic crystals</strong> typically contain fewer atoms per structure and exhibit high degrees of <strong>symmetry</strong>. However, they lack natural subunits, making them difficult to decompose or simplify for modeling.</li> <li><strong>MOFs</strong>, in contrast, often consist of hundreds to thousands of atoms per structure. Fortunately, their <strong>modular nature</strong> allows them to be decomposed into well-defined building blocks: metal nodes and organic linkers.</li> </ul> <table> <thead> <tr> <th> </th> <th><strong>Inorganic</strong></th> <th><strong>MOF</strong></th> </tr> </thead> <tbody> <tr> <td>Size</td> <td>~10-50 atoms/structure</td> <td>~50-2000 atoms/structure</td> </tr> <tr> <td>Key structural trait</td> <td>Symmetry-rich</td> <td>Modular</td> </tr> <tr> <td>Generation challenge</td> <td>Capturing symmetry</td> <td>Scaling to large structures</td> </tr> </tbody> </table> <p>In this blogpost, we explore two recent generative models that address these distinct challenges:</p> <ul> <li><strong>SymmCD (ICLR 2025)</strong><d-cite key="levy2025symmcd"></d-cite> targets <em>inorganic crystals</em> using a diffusion model that explicitly incorporates <em>symmetry</em>. By learning to generate only the <em>asymmetric unit</em> and expanding it via symmetry operations, it ensures validity and efficiency in generation.</li> <li><strong>MOFDiff (ICLR 2024)</strong><d-cite key="fu2023mofdiff"></d-cite> focuses on <em>MOFs</em> by leveraging their modularity through a <em>coarse-grained representation</em>. By learning to generate the coarse-grained representation, MOFDiff succesffully generates large and complex MOF structures.</li> </ul> <p>The following table provides a quick <strong>summary</strong> of the two works:</p> <table> <thead> <tr> <th> </th> <th><strong>SymmCD</strong></th> <th><strong>MOFDiff</strong></th> </tr> </thead> <tbody> <tr> <td>Target material</td> <td>Inorganic crystals</td> <td>Metal-organic frameworks</td> </tr> <tr> <td>Dataset</td> <td>Materials Project<d-cite key="Jain2013"></d-cite></td> <td>BW-DB<d-cite key="boyd2019data"></d-cite></td> </tr> <tr> <td>Key idea</td> <td>Generate asymmetric unit and reconstruct full structure using symmetry</td> <td>Generate coarse-grained MOF structure based the modular nature of MOFs</td> </tr> <tr> <td>Method</td> <td>Diffusion</td> <td>Diffusion</td> </tr> <tr> <td>Model backbone</td> <td>Periodic E(3)-equivariant GNN</td> <td>Periodic SE(3)-equivariant GNN</td> </tr> <tr> <td>Publication</td> <td>ICLR 2025</td> <td>ICLR 2024</td> </tr> </tbody> </table> <h2 id="symmcd-symmetry-preserving-crystal-generation-with-diffusion-models">SymmCD: Symmetry-Preserving Crystal Generation with Diffusion Models</h2> <h3 id="preliminary-representing-crystals">Preliminary: Representing Crystals</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/unit_cell-480.webp 480w,/assets/img/2025-04-28-_nayoung/unit_cell-800.webp 800w,/assets/img/2025-04-28-_nayoung/unit_cell-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/unit_cell.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Figure 2. The unit cell representation of a crystal. The ideal, infinite crystal structure can be recovered by replicating the cell along the three lattice vectors.</figcaption> </figure> <p>To represent a 3D structure of a <strong>molecule</strong> with \(N\) atoms, we typically specify two components:</p> <ol> <li>The atom types \(\bA=(a_1, \dots, a_N) \in \cA^N\), where each \(\cA\) is the set of possible elements,</li> <li>The 3D coordinates of those atoms, \(\bX=(x_1, \dots, x_N) \in \bbR^{N \times 3}\).</li> </ol> <p><strong>Crystals</strong> are similar, but with one key addition: the <strong>lattice</strong>. The lattice is defined by three lattice vectors \(\mathbf{L}=(l_1, l_2, l_3) \in \bbR^{N \times 3}\) which describe how the unit cell repeasts in space. This compact <strong>unit cell representation</strong> \(\cM = (\bA, \bX, \bL)\) contains all the information needed to define a crystal. By translating the atoms along the lattice vectors \(l_1, l_2, l_3\), we can reconstruct the full (theorectically infinite) periodic structure of the crystal (Figure 2).</p> <h3 id="asymmetric-unit-and-site-symmetries">Asymmetric Unit and Site Symmetries</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/asymmetric_unit-480.webp 480w,/assets/img/2025-04-28-_nayoung/asymmetric_unit-800.webp 800w,/assets/img/2025-04-28-_nayoung/asymmetric_unit-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/asymmetric_unit.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Figure 3. (left) An asymmetric unit can be unfolded using symmetry operations to reconstruct the full unit cell. (right) SymmCD generates the asymmetric unit, which contains the atom types, coordinates, lattice, and site symmetries.</figcaption> </figure> <p>While the unit cell representation \(\cM = (\bA, \bX, \bL)\) compactly represents a crystal, <strong>SymmCD</strong> uses an even smaller representation: the <strong>asymmetric unit</strong>. The asymmetric unit can be combined with crystal symmetry operations to reconstruct the full unit cell (Figure 3, <em>left</em>).</p> <p>A useful analogy for understanding the asymmetric unit is <em>cutting a paper snowflake</em><d-cite key="fredericks2021pyxtal"></d-cite>: the folded paper represents the asymmetrc unit, and unfolding aplies the symmetry to create the full pattern of the paper snowflake.</p> <p>But here’s the subtle part: <em>where</em> you make the cut affects how many times it appears in the final pattern. For instance, a cut at the center of the folded paper is repeated six times, while a cut at an edge appears three times. In crystallography, this concept is captured by the <strong>site symmetry</strong> – it tells you <em>how</em> to replicate an atom based on its position on the asymmetric unit.</p> <p>SymmCD leverages these two simple concepts for inorganic crystal generation. Rather than generating the full crystal, it generates just the asymmetric unit, which contains the atom types, coordinates, lattice, and site symmetries (Figure 3, <em>right</em>). This simplifies the generation process while guaranteeing that the resulting structures are symmetric.</p> <p>Mathematically, we represent an asymmetric unit with:</p> <ul> <li>Atom types \(\bA' = (a_1, \dots, a_M) \in \cA^M\),</li> <li>3D coordinates \(\bX=(x_1, \dots, x_M) \in \bbR^{M \times 3}\),</li> <li>Asymmetric lattice \(\mathbf{k} \in \mathbb{R}^6\) (see the paper<d-cite key="levy2025symmcd"></d-cite> for details), and</li> <li>Site symmetries \(\bS = (S_{x_1'}, \dots, S_{x_M'}) \in \mathcal{P}^M\), where \(\mathcal{P}\) denotes the set of all possible site symmetries.</li> </ul> <p>Note that \(M \leq N\), since the asymmetric unit contains only a subset of the atoms in the full unit cell.</p> <h3 id="symmcd-pre-processing-training-and-sampling">SymmCD: Pre-processing, Training, and Sampling</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/symmcd_pipeline-480.webp 480w,/assets/img/2025-04-28-_nayoung/symmcd_pipeline-800.webp 800w,/assets/img/2025-04-28-_nayoung/symmcd_pipeline-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/symmcd_pipeline.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Figure 4. The full pipeline of SymmCD, including pre-processing, training, sampling, and post-processing.</figcaption> </figure> <h4 id="pre-processing-extracting-the-asymmetric-unit">Pre-processing: Extracting the Asymmetric Unit</h4> <p>Recall that the key idea of SymmCD is to model the <strong>asymmetric unit</strong> instead of the entire unit cell. Now, the question is <em>how</em> extract the asymmetric unit given an unit cell.</p> <p>It turns out that <em>all</em> crystals fall into just 230 possible space groups, each encoding a unique combination of symmetry operations. Given a crystal in unit cell form, \(\cM = (\bA, \bX, \bL)\), we first identify its space group \(G\) (there are python packages built for this purpose – e.g., spglib). This space group tells us how the crystal repeats and, in turn, defines its asymmetric unit.</p> \[\begin{equation} \mathcal{D} = \{ (\bA, \bX, \bL) \} \Rightarrow{} \mathcal{D} = \{ (G, k, \bA', \bX', \bS) \}. \end{equation}\] <h4 id="training-the-model">Training the Model</h4> <p>SymmCD models the joint distribution as: \(\begin{equation} p_{\theta}(G, k, \bA', \bX', \bS)=p_{\theta}( k, \bA', \bX', \bS \vert G)p(G). \end{equation}\)</p> <p>In other words, once a space group \(G\) is specified (or sampled), the model learns to generate the corresponding asymmetric unit. To do this, SymmCD uses a diffusion model, where the atom types and site symmetries \(\bA', \bS\) are learned with discrete diffusion and the lattice \(k, \bX'\) are learned with continuous diffusion.</p> <h4 id="sampling-and-post-processing">Sampling and Post-processing</h4> <p>Generating inorganic crystal structures with SymmCD is straightforward: (1) Choose a space group \(G\) – either randomly or specifying, (2) Sample \((k, \bA', \bX', \bS) \sim p_{\theta}( k, \bA', \bX', \bS \vert G)\) with the trained diffusion model, and (3) Project atoms into valid <strong>Wyckoff positions</strong> based on their site symmetries.</p> <p>Why is this projection needed? Recall the paper snowflake analogy: cuts made at different parts of the folded paper produce different numbers of copies. Similarly, certain regions of the asymmetric unit only permit specific site symmetries. If a generated atom-site symmetry pair is incompatible, we adjust (i.e., project) the atom’s position to a compatible one.</p> <p>Finally, we replicate the asymmetric unit using its site symmetries to reconstruct the full crystal \(\cM = (\bA, \bX, \bL)\). By shifting the focus from full crystals to asymmetric unit, SymmCD enjoys higher computational efficiency.</p> <h3 id="experimental-results-what-advantages-does-symmcd-have">Experimental results: what advantages does SymmCD have?</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/symmcd_results-480.webp 480w,/assets/img/2025-04-28-_nayoung/symmcd_results-800.webp 800w,/assets/img/2025-04-28-_nayoung/symmcd_results-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/symmcd_results.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Results.</figcaption> </figure> <p>In the experiments, we randomly generate 10,000 crystals in each baseline and identify the proportion of space group symmetries. The experiments show that both SymmCD and DiffCSP++<d-cite key="jiaospace"></d-cite> generates samples with <em>diverse</em> space group symmetries. Yet, SymmCD is able to generate more <em>novel</em> structures that are not in the training dataset. This is because DiffCSP++ starts with a template extracted from the training dataset and refine it with their model.</p> <h2 id="mofdiff-coarse-grained-diffusion-for-metal-organic-framework-design">MOFDiff: Coarse-grained Diffusion for Metal-Organic Framework Design</h2> <h3 id="preliminary-coarse-grained-representation-for-mofs">Preliminary: Coarse-grained representation for MOFs</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/mof_representation-480.webp 480w,/assets/img/2025-04-28-_nayoung/mof_representation-800.webp 800w,/assets/img/2025-04-28-_nayoung/mof_representation-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/mof_representation.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Results.</figcaption> </figure> <p>Metal–Organic Frameworks (MOFs) are some of the most structurally complex materials known. Compared to inorganic crystals, they’re much larger, often containing hundreds to thousands of atoms per unit cell. This scale makes direct generation at the atomic level both inefficient and error-prone for traditional generative models.</p> <p>Fortunately, MOFs come with a built-in advantage: modularity. Each MOF is composed of repeating building blocks—metal clusters and organic linkers—that connect in well-defined ways. This modularity lets us step back and see MOFs not as clouds of atoms, but as assemblies of interacting components.</p> <p>Instead of representing MOFs as full atomic structures \((\bA, \bX, \bL)\), MOFDiff uses a simplified, coarse-grained representation \(\begin{equation} \cM^C = (\bA^C, \bX^C, \bL) \end{equation}\) where:</p> <ul> <li>\(\bA^C = (a_1^C, \dots, a_K^C) \in \mathbb{B}^{K}\) are the building block types (e.g., a specific metal node or linker),</li> <li>\(\bX^C = (x_1^C, \dots x_k^C) \in \bbR^{K \times 3}\) are their 3D Cartesian coordinates, and</li> <li>\(\bL\) is the lattice that defines periodicity (same).</li> </ul> <p>Because the number of building blocks \(K\) is often orders of magnitude smaller than the number of atoms \(N\) (i.e., \(K \ll N\)), this representation is much more efficient to model.</p> <p>And that’s the core idea behind MOFDiff—instead of modeling the full atomic structure, it learns a score-based diffusion model over a simplified, coarse-grained representation of MOFs.</p> <h3 id="learning-building-block-representations">Learning building block representations</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/contrastive_learning-480.webp 480w,/assets/img/2025-04-28-_nayoung/contrastive_learning-800.webp 800w,/assets/img/2025-04-28-_nayoung/contrastive_learning-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/contrastive_learning.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Results.</figcaption> </figure> <p>But how do we represent these building blocks effectively?</p> <p>A naive approach might be to extract all building blocks from the training dataset, assign each a one-hot ID, and then train a diffusion model: discrete diffusion for the building block types \(\bA^c\), and continuous diffusions for their positions \(\bX^C\) and lattice \(\bL\).</p> <p>However, this naive strategy quickly falls apart. The training dataset contains millions of building blocks—around 2 million extracted from 289k MOFs—which makes one-hot encoding extremely sparse and hard to learn. Even worse, many of these building blocks are topologically identical—they have the same atom and bond structure (i.e., same 2D graph), differing only slightly in 3D geometry, making this representation very inefficient.</p> <p>To overcome this, MOFDiff learns a <strong>dense</strong>, <strong>continuous</strong> embedding \(\bA^C\) for each building block that captures topological similarity while remaining efficient to model. It does this by training a <strong>SE(3)-invariant graph neural network</strong> takes as input the \(i\) building block (i.e., its atom types and coordinates) and outputs a dense embedding \(\mathbf{b}_i \in \bbR^d\) corresponding to that building block.</p> <p>To ensure that the learned embeddings group similar building blocks together, MOFDiff uses a <strong>contrastive learning objective</strong>. It first computes 2D fingerprints (ECFP4) to define molecular similarity, and then trains the model to bring structurally similar blocks close in embedding space.</p> <p>The contrastive loss is defined as:</p> <p>\(\begin{equation} \mathcal{L}_C = - \log \sum_{i \in \mathbf{B}} \frac{\sum_{j \in \mathbf{B}_i^{+}} \exp(s_{i,j} / \tau)}{\frac{\sum_{j \in \mathbf{B}_i^{+}} \exp(s_{i,j} / \tau)} \end{equation}\) where</p> <ul> <li>$\mathbf{B}$ is a batch of building blocks,</li> <li>$\mathbf{B}_i^{+} \subseteq \mathbf{B}$ are building blocks with the same ECFP4 fingerprint as $i$,</li> <li>$s_{i,j}$ is the <em>cosine similarity</em> between projected building block embeddings:<br/> \(\begin{equation} s_{i,j} = \frac{\mathbf{p}_i^{\top} \mathbf{p}_j}{\|\mathbf{p}_i\| \|\mathbf{p}_j\|}, \quad \mathbf{p}_i = \operatorname{MLP}(\mathbf{b}_i) \end{equation}\)</li> <li>$\tau$ is the temperature.</li> </ul> <p>Once trained, this encoder maps each building block to a dense embedding. All MOFs in the dataset can then be transformed into their coarse-grained representation \(\cM = (\bA, \bX, \bL)\), where \(\bA^C = (\mathbf{b}_1, \dots, \mathbf{b}_K) \in \bbR^{K \times d}\) with \(d=32\) – a far more compact representation than a one-hot encoding over ~2M types of building blocks.</p> <h3 id="training-mofdiff">Training MOFDiff</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/mofdiff_training-480.webp 480w,/assets/img/2025-04-28-_nayoung/mofdiff_training-800.webp 800w,/assets/img/2025-04-28-_nayoung/mofdiff_training-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/mofdiff_training.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Results.</figcaption> </figure> <p>With the coarse-grained representation in place, it’s time to train the generative model.</p> <p>MOFDiff aims to model the full joint distribution over the coarse-grained structure and an auxiliary latent variable \(\mathbf{z}\): \(\begin{equation} p_{\theta}(\bA^C, \bX^C, \bL, K, z) = p_{\theta}(L, K \vert \mathbf{z}) p_{\theta}(\bA^c, \bX^C \vert L, k, \mathbf{z}), \end{equation}\) where:</p> <ul> <li>\(\bA^C=(\mathbf{b}_1, \dots, \mathbf{b}_K) \in \bbR^{K \times d}\) and \(\bX^C = (x_1^C, \dots x_k^C) \in \bbR^{K \times 3}\) are the building block types and positions with \(K\) as the number of building blocks,</li> <li>\(\bL\) is the lattice,</li> <li>\(\mathbf{z}\) is a latent vector used for generating the \(\bL\), \(K\).</li> </ul> <p>This distribution is factorized as: \(\begin{equation} p_{\theta}(\bA^C, \bX^C, \bL, K, z) = p_{\theta}(L, K \vert \mathbf{z}) p_{\theta}(\bA^c, \bX^C \vert L, K, \mathbf{z}). \end{equation}\) Here, the first part, \(p_{\theta}(L, K \vert \mathbf{z})\) is modeled using an MLP: \(\begin{equation} \hat{\bL}, \hat{K} = \operatorname{MLP}_{\bL, K}(\mathbf{z}), \end{equation}\) while the second part, \(p_{\theta}(\bA^c, \bX^C \vert L, k, \mathbf{z})\) is modeled using score-based diffusion, where a periodic graph neural network denoiser \(\operatorname{PGNN}_D\) predicts the noise in the atom types and coordinates as: \(\begin{equation} \mathbf{s}_{\bA^C}, \mathbf{s}_{\bX^C} = \operatorname{PGNN}_D(\tilde{\cM}_t^C, z), \end{equation}\) where \(\tilde{\cM}_t^C=(\bA_t^C, \bX_t^C, \bL)\) is the noised version of the coarse-grained structure at timestep \(t\), and \(\mathbf{z}\) is the latent vector produced with a periodict graph neural network encoder \(\operatorname{PGNN}_E\): $$ \begin{equation} \mathbf{z} = \operatorname{PGNN}_E(\cM^C). \end{equation}</p> <p>where \(p_{\theta}(L, K \vert \mathbf{z})\) simply learned as a degenerate distribution with \(\hat{\bL}, \hat{K} = \operatorname{MLP_{\bL, K}(mathbf{z})\) and \(p_{\theta}(\bA^c, \bX^C \vert L, k, \mathbf{z})\) is learned with a denoiser for score-based diffusion as: \(\mathbf{s}_{\bA^C}, \mathbf{s}_{\bX^C} = \operatorname{PGNN}_D(\tilde{\cM}_t^C, z)\), where \(\operatorname{PGNN}_D\) is a periodic graph-neural network (we omit \(K\) since it is implictly included as the dimension). The additional latent representation \(\mathbf{z}\) is learned with an encoder as \(\mathbf{z} = \operatorname{PGNN}_E(\cM^C)\), where \(\operatorname{PGNN}_E\) is a periodic graph neural network encoder as well.</p> <h4 id="objective-function">Objective function</h4> <p>The denoiser \(\operatorname{PGNN}_D(\cM_t^C, z)\) is trained using the standard denoising score objective: \(\begin{equation} \mathcal{L}_{\boldsymbol{A}}=\mathbb{E}_{t, \boldsymbol{M}^C, \boldsymbol{\epsilon}_{\boldsymbol{A}}}\left[\left\|\boldsymbol{\epsilon}_{\boldsymbol{A}}-\boldsymbol{s}_{\boldsymbol{A}_t^C, \boldsymbol{z}}\right\|^2\right], \quad \mathcal{L}_{\boldsymbol{X}}=\mathbb{E}_{t, \boldsymbol{M}^C, \boldsymbol{\epsilon}_{\boldsymbol{X}}}\left[\sigma_t^2\left\|\boldsymbol{\epsilon}_{\boldsymbol{X}}-\boldsymbol{s}_{\boldsymbol{X}_t^C, \boldsymbol{z}}\right\|^2\right]. \end{equation}\) \(\operatorname{MLP}_{\bL, K}(\mathbf{z})\) is supervised with the mean squared error and cross-entropy losses: \(\begin{equation} \mathcal{L}_{\boldsymbol{L}, K}=\|\boldsymbol{L}-\hat{\boldsymbol{L}}\|^2+\operatorname{CrossEntropy}(K, \hat{K}). \end{equation}\) Finally, the encoder \(\operatorname{PGNN}_E\) is regularized with a KL divergence \(\mathcal{L}_{\mathrm{KL}}\) to match a standard normal prior.</p> <p>The overall training objective for MOFDiff combines all components as: \(\begin{equation} \mathcal{L}_{\text {MOFDiff }}=\mathcal{L}_{\boldsymbol{A}}+\mathcal{L}_{\boldsymbol{X}}+\mathcal{L}_{\boldsymbol{L}, K}+\beta_{\mathrm{KL}} \mathcal{L}_{\mathrm{KL}}. \end{equation}\) where \(\beta_{\mathrm{KL}}\) is a hyperparameter that controls the strength of KL regularization, set to 0.01.</p> <h3 id="sampling-pipeline-for-mofdiff">Sampling pipeline for MOFDiff</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/mofdiff_sampling-480.webp 480w,/assets/img/2025-04-28-_nayoung/mofdiff_sampling-800.webp 800w,/assets/img/2025-04-28-_nayoung/mofdiff_sampling-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/mofdiff_sampling.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Results.</figcaption> </figure> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/self_assembly-480.webp 480w,/assets/img/2025-04-28-_nayoung/self_assembly-800.webp 800w,/assets/img/2025-04-28-_nayoung/self_assembly-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/self_assembly.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Results.</figcaption> </figure> <p>Once MOFDiff is trained, we can generate a new MOF structure with the following process:</p> <ol> <li><strong>Sample</strong> a random latent code \(\mathbf{z} \sim \mathcal{N}(0,I)\).</li> <li><strong>Predict</strong> the lattice and number of building blocks: \(\begin{equation} \hat{\bL}, \hat{K} = \operatorname{MLP}_{\bL, K}(mathbf{z}) \end{equation}\)</li> <li><strong>Run denoising diffusion</strong> with the trained denoiser \(\operatorname{PGNN}_D(\tilde{\cM}_t^C, z)\) to generate the coarse-grained structure \((\bA^C, \bX^C, \bL)\).</li> </ol> <p>At this point, we have a <strong>coarse-grained MOF</strong>. We now need to recover the full atomic structure with fine-graned details. Here’s how:</p> <ol> <li><strong>Building block decoding</strong>. For each generated embedding \(\bA^C\), we retrieve the building block from the training dataset with the closest embedding with nearest neighbor search. This gives us the actual atom types and coordinates of the building block.</li> <li><strong>Self-assembly (orientation prediction)</strong>. Since we have only predicted the center of mass of each building block with \(\bX^C\), we now need to know <em>how to orient them</em>. MOFDiff uses an optimization-based <strong>sef-assembly algorithm</strong> to find the rotation that maximizes the alignment of connection points between the building blocks. This maximizes the connectivity and minimizes the gaps between the metal nodes and organic linkers.</li> <li><strong>Force field relaxation</strong>. Finally, the assembled structure undergoes relaxation with energy minimziation with the UFF force field. This step ensures that we can make a final fine-grained refinement to get a physical structure.</li> </ol> <h3 id="evaluation-results">Evaluation results</h3> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/2025-04-28-_nayoung/mofdiff_results-480.webp 480w,/assets/img/2025-04-28-_nayoung/mofdiff_results-800.webp 800w,/assets/img/2025-04-28-_nayoung/mofdiff_results-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/2025-04-28-_nayoung/mofdiff_results.png" class="img-fluid" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> <figcaption class="caption">Results.</figcaption> </figure> <h4 id="generating-valid-novel-and-unique-mofs">Generating valid, novel, and unique MOFs</h4> <p>How does MOFDiff perform in practice? To evaluate it, the authors sampled 10,000 MOF structures and assessed them on three key metrics: <strong>validity</strong>, <strong>novelty</strong>, and <strong>uniqueness</strong>.</p> <ul> <li><strong>Validity</strong>: A structure is considered valid if it passes the check with a python package called <code class="language-plaintext highlighter-rouge">MOFchecker</code>, which assess whether a MOF is chemically and physicall valid based on a set of criteria including the presence of at least one metal, carbon, and hydrogen atom, overlapping atoms, and valency.</li> <li><strong>Novelty</strong>: A structure is novel if it nodes not exist in the training dataset. This is measured with <code class="language-plaintext highlighter-rouge">MOFid</code>, which computes a unique identifier for a MOF baesd on its building blocks and connectivity.Make</li> <li><strong>Uniqueness</strong>: We find the unique structures by filtering out the duplicates from the generated set of structures.</li> </ul> <p>Out of 10,000 generated structures, <strong>3,012 passed the validity check</strong> and <strong>2,998</strong> were <strong>valid</strong>, <strong>novely</strong>, and <strong>unique</strong>. That’s nearly 3,000 high-quality MOFs generated from scratch – an impressive result given the structural complexity and the size of MOFs.</p> <h4 id="discovering-high-performing-mofs-for-carbon-capture">Discovering high-performing MOFs for carbon capture</h4> <p>Thanks to the latent variable \(\mathbf{z}\), MOFDiff can also be used for property-guided generation.</p> <p>Suppose you want to discover MOFs with high CO$<em>{2}$ working capacity – a key metric for carbon capture technology. MOFDiff enables this by learning a simple property predictor during training: \(\begin{equation} \hat{\mathbf{c}} = \operatorname{MLP}_P(\mathbf{z}), \end{equation}\) where \(\mathbf{c}\) is the property of interest (e.g., CO$</em>{2}$ capacity). The predictor is trained with the mean squared error loss using known property labels.</p> <p>Then, during sampling, MOFDiff generates many latent codes \(\mathbf{z} \sim \mathcal{N}(0, I)\), computes the CO$_{2}$ working capacity \(\hat{\mathbf{c}}\), and filters for those with high CO@ working capacity.</p> <p>In experiments, this approach successfully generates MOFs with higher CO$_{2}$ working capcity than those in the training dataset, demonstrating MOFDiff’s potential for targeted material discovery.</p>]]></content><author><name>Nayoung Kim</name></author><summary type="html"><![CDATA[In this work, we review to recent works on materials generation. One is SymmCD, which generates inorganic crystals by exploiting the special symmetry property of crystals called 'space groups'. The other is MOFDiff, a coarse-grained diffusion model that generates metal-organic frameworks (MOFs) by exploiting the modular nature of MOFs.]]></summary></entry><entry><title type="html">Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra</title><link href="https://nayoung10.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/" rel="alternate" type="text/html" title="Google Gemini updates: Flash 1.5, Gemma 2 and Project Astra"/><published>2024-05-14T00:00:00+00:00</published><updated>2024-05-14T00:00:00+00:00</updated><id>https://nayoung10.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra</id><content type="html" xml:base="https://nayoung10.github.io/blog/2024/google-gemini-updates-flash-15-gemma-2-and-project-astra/"><![CDATA[]]></content><author><name></name></author><summary type="html"><![CDATA[We’re sharing updates across our Gemini family of models and a glimpse of Project Astra, our vision for the future of AI assistants.]]></summary></entry><entry><title type="html">a post with tabs</title><link href="https://nayoung10.github.io/blog/2024/tabs/" rel="alternate" type="text/html" title="a post with tabs"/><published>2024-05-01T00:32:13+00:00</published><updated>2024-05-01T00:32:13+00:00</updated><id>https://nayoung10.github.io/blog/2024/tabs</id><content type="html" xml:base="https://nayoung10.github.io/blog/2024/tabs/"><![CDATA[<p>This is how a post with <a href="https://github.com/Ovski4/jekyll-tabs">tabs</a> looks like. Note that the tabs could be used for different purposes, not only for code.</p> <h2 id="first-tabs">First tabs</h2> <p>To add tabs, use the following syntax:</p> <div class="language-liquid highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="cp">{%</span><span class="w"> </span><span class="nt">tabs</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-1</span><span class="w"> </span><span class="cp">%}</span>

Content 1

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">tab</span><span class="w"> </span><span class="nv">group-name</span><span class="w"> </span><span class="nv">tab-name-2</span><span class="w"> </span><span class="cp">%}</span>

Content 2

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtab</span><span class="w"> </span><span class="cp">%}</span>

<span class="cp">{%</span><span class="w"> </span><span class="nt">endtabs</span><span class="w"> </span><span class="cp">%}</span>
</code></pre></div></div> <p>With this you can generate visualizations like:</p> <ul id="log" class="tab" data-tab="e7f6d372-5cef-4409-b01d-18e6f78bd30b" data-name="log"> <li class="active" id="log-php"> <a href="#">php </a> </li> <li id="log-js"> <a href="#">js </a> </li> <li id="log-ruby"> <a href="#">ruby </a> </li> </ul> <ul class="tab-content" id="e7f6d372-5cef-4409-b01d-18e6f78bd30b" data-name="log"> <li class="active"> <div class="language-php highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">var_dump</span><span class="p">(</span><span class="s1">'hello'</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">console</span><span class="p">.</span><span class="nf">log</span><span class="p">(</span><span class="dl">"</span><span class="s2">hello</span><span class="dl">"</span><span class="p">);</span>
</code></pre></div></div> </li> <li> <div class="language-javascript highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nx">pputs</span> <span class="dl">'</span><span class="s1">hello</span><span class="dl">'</span>
</code></pre></div></div> </li> </ul> <h2 id="another-example">Another example</h2> <ul id="data-struct" class="tab" data-tab="83f68628-d7ba-4576-a59f-a761f1ff43b3" data-name="data-struct"> <li class="active" id="data-struct-yaml"> <a href="#">yaml </a> </li> <li id="data-struct-json"> <a href="#">json </a> </li> </ul> <ul class="tab-content" id="83f68628-d7ba-4576-a59f-a761f1ff43b3" data-name="data-struct"> <li class="active"> <div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">hello</span><span class="pi">:</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">whatsup"</span>
  <span class="pi">-</span> <span class="s2">"</span><span class="s">hi"</span>
</code></pre></div></div> </li> <li> <div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">{</span><span class="w">
  </span><span class="nl">"hello"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="s2">"whatsup"</span><span class="p">,</span><span class="w"> </span><span class="s2">"hi"</span><span class="p">]</span><span class="w">
</span><span class="p">}</span><span class="w">
</span></code></pre></div></div> </li> </ul> <h2 id="tabs-for-something-else">Tabs for something else</h2> <ul id="something-else" class="tab" data-tab="3ae01eba-0449-4fed-81c4-e7b67f0d09ce" data-name="something-else"> <li class="active" id="something-else-text"> <a href="#">text </a> </li> <li id="something-else-quote"> <a href="#">quote </a> </li> <li id="something-else-list"> <a href="#">list </a> </li> </ul> <ul class="tab-content" id="3ae01eba-0449-4fed-81c4-e7b67f0d09ce" data-name="something-else"> <li class="active"> <p>Regular text</p> </li> <li> <blockquote> <p>A quote</p> </blockquote> </li> <li> <p>Hipster list</p> <ul> <li>brunch</li> <li>fixie</li> <li>raybans</li> <li>messenger bag</li> </ul> </li> </ul>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is what included tabs in a post could look like]]></summary></entry><entry><title type="html">a post with typograms</title><link href="https://nayoung10.github.io/blog/2024/typograms/" rel="alternate" type="text/html" title="a post with typograms"/><published>2024-04-29T23:36:10+00:00</published><updated>2024-04-29T23:36:10+00:00</updated><id>https://nayoung10.github.io/blog/2024/typograms</id><content type="html" xml:base="https://nayoung10.github.io/blog/2024/typograms/"><![CDATA[<p>This is an example post with some <a href="https://github.com/google/typograms/">typograms</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">+----+
|    |---&gt; My first diagram!
+----+</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-typograms">+----+
|    |---&gt; My first diagram!
+----+
</code></pre> <p>Another example:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">typograms
</span><span class="sb">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.</span>
<span class="p">```</span>
</code></pre></div></div> <p>which generates:</p> <pre><code class="language-typograms">.------------------------.
|.----------------------.|
||"https://example.com" ||
|'----------------------'|
| ______________________ |
||                      ||
||   Welcome!           ||
||                      ||
||                      ||
||  .----------------.  ||
||  | username       |  ||
||  '----------------'  ||
||  .----------------.  ||
||  |"*******"       |  ||
||  '----------------'  ||
||                      ||
||  .----------------.  ||
||  |   "Sign-up"    |  ||
||  '----------------'  ||
||                      ||
|+----------------------+|
.------------------------.
</code></pre> <p>For more examples, check out the <a href="https://google.github.io/typograms/#examples">typograms documentation</a>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="diagrams"/><summary type="html"><![CDATA[this is what included typograms code could look like]]></summary></entry><entry><title type="html">a post that can be cited</title><link href="https://nayoung10.github.io/blog/2024/post-citation/" rel="alternate" type="text/html" title="a post that can be cited"/><published>2024-04-28T15:06:00+00:00</published><updated>2024-04-28T15:06:00+00:00</updated><id>https://nayoung10.github.io/blog/2024/post-citation</id><content type="html" xml:base="https://nayoung10.github.io/blog/2024/post-citation/"><![CDATA[<p>This is an example post that can be cited. The content of the post ends here, while the citation information is automatically provided below. The only thing needed is for you to set the <code class="language-plaintext highlighter-rouge">citation</code> key in the front matter to <code class="language-plaintext highlighter-rouge">true</code>.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="citation"/><summary type="html"><![CDATA[this is what a post that can be cited looks like]]></summary></entry><entry><title type="html">a post with pseudo code</title><link href="https://nayoung10.github.io/blog/2024/pseudocode/" rel="alternate" type="text/html" title="a post with pseudo code"/><published>2024-04-15T00:01:00+00:00</published><updated>2024-04-15T00:01:00+00:00</updated><id>https://nayoung10.github.io/blog/2024/pseudocode</id><content type="html" xml:base="https://nayoung10.github.io/blog/2024/pseudocode/"><![CDATA[<p>This is an example post with some pseudo code rendered by <a href="https://github.com/SaswatPadhi/pseudocode.js">pseudocode</a>. The example presented here is the same as the one in the <a href="https://saswat.padhi.me/pseudocode.js/">pseudocode.js</a> documentation, with only one simple but important change: everytime you would use <code class="language-plaintext highlighter-rouge">$</code>, you should use <code class="language-plaintext highlighter-rouge">$$</code> instead. Also, note that the <code class="language-plaintext highlighter-rouge">pseudocode</code> key in the front matter is set to <code class="language-plaintext highlighter-rouge">true</code> to enable the rendering of pseudo code. As an example, using this code:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">pseudocode
</span><span class="sb">% This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
\begin{algorithm}
\caption{Quicksort}
\begin{algorithmic}
\PROCEDURE{Quicksort}{$$A, p, r$$}
    \IF{$$p &lt; r$$}
        \STATE $$q = $$ \CALL{Partition}{$$A, p, r$$}
        \STATE \CALL{Quicksort}{$$A, p, q - 1$$}
        \STATE \CALL{Quicksort}{$$A, q + 1, r$$}
    \ENDIF
\ENDPROCEDURE
\PROCEDURE{Partition}{$$A, p, r$$}
    \STATE $$x = A[r]$$
    \STATE $$i = p - 1$$
    \FOR{$$j = p$$ \TO $$r - 1$$}
        \IF{$$A[j] &lt; x$$}
            \STATE $$i = i + 1$$
            \STATE exchange
            $$A[i]$$ with $$A[j]$$
        \ENDIF
        \STATE exchange $$A[i]$$ with $$A[r]$$
    \ENDFOR
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Generates:</p> <pre><code class="language-pseudocode">% This quicksort algorithm is extracted from Chapter 7, Introduction to Algorithms (3rd edition)
\begin{algorithm}
\caption{Quicksort}
\begin{algorithmic}
\PROCEDURE{Quicksort}{$$A, p, r$$}
    \IF{$$p &lt; r$$}
        \STATE $$q = $$ \CALL{Partition}{$$A, p, r$$}
        \STATE \CALL{Quicksort}{$$A, p, q - 1$$}
        \STATE \CALL{Quicksort}{$$A, q + 1, r$$}
    \ENDIF
\ENDPROCEDURE
\PROCEDURE{Partition}{$$A, p, r$$}
    \STATE $$x = A[r]$$
    \STATE $$i = p - 1$$
    \FOR{$$j = p$$ \TO $$r - 1$$}
        \IF{$$A[j] &lt; x$$}
            \STATE $$i = i + 1$$
            \STATE exchange
            $$A[i]$$ with $$A[j]$$
        \ENDIF
        \STATE exchange $$A[i]$$ with $$A[r]$$
    \ENDFOR
\ENDPROCEDURE
\end{algorithmic}
\end{algorithm}
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is what included pseudo code could look like]]></summary></entry><entry><title type="html">a post with code diff</title><link href="https://nayoung10.github.io/blog/2024/code-diff/" rel="alternate" type="text/html" title="a post with code diff"/><published>2024-01-27T19:22:00+00:00</published><updated>2024-01-27T19:22:00+00:00</updated><id>https://nayoung10.github.io/blog/2024/code-diff</id><content type="html" xml:base="https://nayoung10.github.io/blog/2024/code-diff/"><![CDATA[<p>You can display diff code by using the regular markdown syntax:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">diff
</span><span class="gh">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
</span><span class="gd">--- a/sample.js
</span><span class="gi">+++ b/sample.js
</span><span class="p">@@ -1 +1 @@</span>
<span class="gd">-console.log("Hello World!")
</span><span class="gi">+console.log("Hello from Diff2Html!")</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <div class="language-diff highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="gh">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
</span><span class="gd">--- a/sample.js
</span><span class="gi">+++ b/sample.js
</span><span class="p">@@ -1 +1 @@</span>
<span class="gd">-console.log("Hello World!")
</span><span class="gi">+console.log("Hello from Diff2Html!")
</span></code></pre></div></div> <p>But this is difficult to read, specially if you have a large diff. You can use <a href="https://diff2html.xyz/">diff2html</a> to display a more readable version of the diff. For this, just use <code class="language-plaintext highlighter-rouge">diff2html</code> instead of <code class="language-plaintext highlighter-rouge">diff</code> for the code block language:</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">diff2html
</span><span class="sb">diff --git a/sample.js b/sample.js
index 0000001..0ddf2ba
--- a/sample.js
+++ b/sample.js
@@ -1 +1 @@
-console.log("Hello World!")
+console.log("Hello from Diff2Html!")</span>
<span class="p">```</span>
</code></pre></div></div> <p>If we use a longer example, for example <a href="https://github.com/rtfpessoa/diff2html/commit/c2c253d3e3f8b8b267f551e659f72b44ca2ac927">this commit from diff2html</a>, it will generate the following output:</p> <pre><code class="language-diff2html">From 2aaae31cc2a37bfff83430c2c914b140bee59b6a Mon Sep 17 00:00:00 2001
From: Rodrigo Fernandes &lt;rtfrodrigo@gmail.com&gt;
Date: Sun, 9 Oct 2016 16:41:54 +0100
Subject: [PATCH 1/2] Initial template override support

---
 scripts/hulk.js                    |  4 ++--
 src/diff2html.js                   |  3 +--
 src/file-list-printer.js           | 11 ++++++++---
 src/hoganjs-utils.js               | 29 +++++++++++++++++------------
 src/html-printer.js                |  6 ++++++
 src/line-by-line-printer.js        |  6 +++++-
 src/side-by-side-printer.js        |  6 +++++-
 test/file-list-printer-tests.js    |  2 +-
 test/hogan-cache-tests.js          | 18 +++++++++++++++---
 test/line-by-line-tests.js         |  3 +--
 test/side-by-side-printer-tests.js |  3 +--
 11 files changed, 62 insertions(+), 29 deletions(-)

diff --git a/scripts/hulk.js b/scripts/hulk.js
index 5a793c18..a4b1a4d5 100755
--- a/scripts/hulk.js
+++ b/scripts/hulk.js
@@ -173,11 +173,11 @@ function namespace(name) {
 // write a template foreach file that matches template extension
 templates = extractFiles(options.argv.remain)
   .map(function(file) {
-    var openedFile = fs.readFileSync(file, 'utf-8');
+    var openedFile = fs.readFileSync(file, 'utf-8').trim();
     var name;
     if (!openedFile) return;
     name = namespace(path.basename(file).replace(/\..*$/, ''));
-    openedFile = removeByteOrderMark(openedFile.trim());
+    openedFile = removeByteOrderMark(openedFile);
     openedFile = wrap(file, name, openedFile);
     if (!options.outputdir) return openedFile;
     fs.writeFileSync(path.join(options.outputdir, name + '.js')
diff --git a/src/diff2html.js b/src/diff2html.js
index 21b0119e..64e138f5 100644
--- a/src/diff2html.js
+++ b/src/diff2html.js
@@ -7,7 +7,6 @@

 (function() {
   var diffParser = require('./diff-parser.js').DiffParser;
-  var fileLister = require('./file-list-printer.js').FileListPrinter;
   var htmlPrinter = require('./html-printer.js').HtmlPrinter;

   function Diff2Html() {
@@ -43,7 +42,7 @@

     var fileList = '';
     if (configOrEmpty.showFiles === true) {
-      fileList = fileLister.generateFileList(diffJson, configOrEmpty);
+      fileList = htmlPrinter.generateFileListSummary(diffJson, configOrEmpty);
     }

     var diffOutput = '';
diff --git a/src/file-list-printer.js b/src/file-list-printer.js
index e408d9b2..1e0a2c61 100644
--- a/src/file-list-printer.js
+++ b/src/file-list-printer.js
@@ -8,11 +8,16 @@
 (function() {
   var printerUtils = require('./printer-utils.js').PrinterUtils;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var baseTemplatesPath = 'file-summary';
   var iconsBaseTemplatesPath = 'icon';

-  function FileListPrinter() {
+  function FileListPrinter(config) {
+    this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   FileListPrinter.prototype.generateFileList = function(diffFiles) {
@@ -38,5 +43,5 @@
     });
   };

-  module.exports.FileListPrinter = new FileListPrinter();
+  module.exports.FileListPrinter = FileListPrinter;
 })();
diff --git a/src/hoganjs-utils.js b/src/hoganjs-utils.js
index 9949e5fa..0dda08d7 100644
--- a/src/hoganjs-utils.js
+++ b/src/hoganjs-utils.js
@@ -8,18 +8,19 @@
 (function() {
   var fs = require('fs');
   var path = require('path');
-
   var hogan = require('hogan.js');

   var hoganTemplates = require('./templates/diff2html-templates.js');

-  var templatesPath = path.resolve(__dirname, 'templates');
+  var extraTemplates;

-  function HoganJsUtils() {
+  function HoganJsUtils(configuration) {
+    this.config = configuration || {};
+    extraTemplates = this.config.templates || {};
   }

-  HoganJsUtils.prototype.render = function(namespace, view, params, configuration) {
-    var template = this.template(namespace, view, configuration);
+  HoganJsUtils.prototype.render = function(namespace, view, params) {
+    var template = this.template(namespace, view);
     if (template) {
       return template.render(params);
     }
@@ -27,17 +28,16 @@
     return null;
   };

-  HoganJsUtils.prototype.template = function(namespace, view, configuration) {
-    var config = configuration || {};
+  HoganJsUtils.prototype.template = function(namespace, view) {
     var templateKey = this._templateKey(namespace, view);

-    return this._getTemplate(templateKey, config);
+    return this._getTemplate(templateKey);
   };

-  HoganJsUtils.prototype._getTemplate = function(templateKey, config) {
+  HoganJsUtils.prototype._getTemplate = function(templateKey) {
     var template;

-    if (!config.noCache) {
+    if (!this.config.noCache) {
       template = this._readFromCache(templateKey);
     }

@@ -53,6 +53,7 @@

     try {
       if (fs.readFileSync) {
+        var templatesPath = path.resolve(__dirname, 'templates');
         var templatePath = path.join(templatesPath, templateKey);
         var templateContent = fs.readFileSync(templatePath + '.mustache', 'utf8');
         template = hogan.compile(templateContent);
@@ -66,12 +67,16 @@
   };

   HoganJsUtils.prototype._readFromCache = function(templateKey) {
-    return hoganTemplates[templateKey];
+    return extraTemplates[templateKey] || hoganTemplates[templateKey];
   };

   HoganJsUtils.prototype._templateKey = function(namespace, view) {
     return namespace + '-' + view;
   };

-  module.exports.HoganJsUtils = new HoganJsUtils();
+  HoganJsUtils.prototype.compile = function(templateStr) {
+    return hogan.compile(templateStr);
+  };
+
+  module.exports.HoganJsUtils = HoganJsUtils;
 })();
diff --git a/src/html-printer.js b/src/html-printer.js
index 585d5b66..13f83047 100644
--- a/src/html-printer.js
+++ b/src/html-printer.js
@@ -8,6 +8,7 @@
 (function() {
   var LineByLinePrinter = require('./line-by-line-printer.js').LineByLinePrinter;
   var SideBySidePrinter = require('./side-by-side-printer.js').SideBySidePrinter;
+  var FileListPrinter = require('./file-list-printer.js').FileListPrinter;

   function HtmlPrinter() {
   }
@@ -22,5 +23,10 @@
     return sideBySidePrinter.generateSideBySideJsonHtml(diffFiles);
   };

+  HtmlPrinter.prototype.generateFileListSummary = function(diffJson, config) {
+    var fileListPrinter = new FileListPrinter(config);
+    return fileListPrinter.generateFileList(diffJson);
+  };
+
   module.exports.HtmlPrinter = new HtmlPrinter();
 })();
diff --git a/src/line-by-line-printer.js b/src/line-by-line-printer.js
index b07eb53c..d230bedd 100644
--- a/src/line-by-line-printer.js
+++ b/src/line-by-line-printer.js
@@ -11,7 +11,8 @@
   var utils = require('./utils.js').Utils;
   var Rematch = require('./rematch.js').Rematch;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var genericTemplatesPath = 'generic';
   var baseTemplatesPath = 'line-by-line';
   var iconsBaseTemplatesPath = 'icon';
@@ -19,6 +20,9 @@

   function LineByLinePrinter(config) {
     this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   LineByLinePrinter.prototype.makeFileDiffHtml = function(file, diffs) {
diff --git a/src/side-by-side-printer.js b/src/side-by-side-printer.js
index bbf1dc8d..5e3033b3 100644
--- a/src/side-by-side-printer.js
+++ b/src/side-by-side-printer.js
@@ -11,7 +11,8 @@
   var utils = require('./utils.js').Utils;
   var Rematch = require('./rematch.js').Rematch;

-  var hoganUtils = require('./hoganjs-utils.js').HoganJsUtils;
+  var hoganUtils;
+
   var genericTemplatesPath = 'generic';
   var baseTemplatesPath = 'side-by-side';
   var iconsBaseTemplatesPath = 'icon';
@@ -26,6 +27,9 @@

   function SideBySidePrinter(config) {
     this.config = config;
+
+    var HoganJsUtils = require('./hoganjs-utils.js').HoganJsUtils;
+    hoganUtils = new HoganJsUtils(config);
   }

   SideBySidePrinter.prototype.makeDiffHtml = function(file, diffs) {
diff --git a/test/file-list-printer-tests.js b/test/file-list-printer-tests.js
index a502a46f..60ea3208 100644
--- a/test/file-list-printer-tests.js
+++ b/test/file-list-printer-tests.js
@@ -1,6 +1,6 @@
 var assert = require('assert');

-var fileListPrinter = require('../src/file-list-printer.js').FileListPrinter;
+var fileListPrinter = new (require('../src/file-list-printer.js').FileListPrinter)();

 describe('FileListPrinter', function() {
   describe('generateFileList', function() {
diff --git a/test/hogan-cache-tests.js b/test/hogan-cache-tests.js
index 190bf6f8..3bb754ac 100644
--- a/test/hogan-cache-tests.js
+++ b/test/hogan-cache-tests.js
@@ -1,6 +1,6 @@
 var assert = require('assert');

-var HoganJsUtils = require('../src/hoganjs-utils.js').HoganJsUtils;
+var HoganJsUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)();
 var diffParser = require('../src/diff-parser.js').DiffParser;

 describe('HoganJsUtils', function() {
@@ -21,16 +21,28 @@ describe('HoganJsUtils', function() {
       });
       assert.equal(emptyDiffHtml, result);
     });
+
     it('should render view without cache', function() {
       var result = HoganJsUtils.render('generic', 'empty-diff', {
         contentClass: 'd2h-code-line',
         diffParser: diffParser
       }, {noCache: true});
-      assert.equal(emptyDiffHtml + '\n', result);
+      assert.equal(emptyDiffHtml, result);
     });
+
     it('should return null if template is missing', function() {
-      var result = HoganJsUtils.render('generic', 'missing-template', {}, {noCache: true});
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)({noCache: true});
+      var result = hoganUtils.render('generic', 'missing-template', {});
       assert.equal(null, result);
     });
+
+    it('should allow templates to be overridden', function() {
+      var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');
+
+      var config = {templates: {'generic-empty-diff': emptyDiffTemplate}};
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
   });
 });
diff --git a/test/line-by-line-tests.js b/test/line-by-line-tests.js
index 1cd92073..8869b3df 100644
--- a/test/line-by-line-tests.js
+++ b/test/line-by-line-tests.js
@@ -14,7 +14,7 @@ describe('LineByLinePrinter', function() {
         '            File without changes\n' +
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
-        '&lt;/tr&gt;\n';
+        '&lt;/tr&gt;';

       assert.equal(expected, fileHtml);
     });
@@ -422,7 +422,6 @@ describe('LineByLinePrinter', function() {
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
         '&lt;/tr&gt;\n' +
-        '\n' +
         '                &lt;/tbody&gt;\n' +
         '            &lt;/table&gt;\n' +
         '        &lt;/div&gt;\n' +
diff --git a/test/side-by-side-printer-tests.js b/test/side-by-side-printer-tests.js
index 76625f8e..771daaa5 100644
--- a/test/side-by-side-printer-tests.js
+++ b/test/side-by-side-printer-tests.js
@@ -14,7 +14,7 @@ describe('SideBySidePrinter', function() {
         '            File without changes\n' +
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
-        '&lt;/tr&gt;\n';
+        '&lt;/tr&gt;';

       assert.equal(expectedRight, fileHtml.right);
       assert.equal(expectedLeft, fileHtml.left);
@@ -324,7 +324,6 @@ describe('SideBySidePrinter', function() {
         '        &lt;/div&gt;\n' +
         '    &lt;/td&gt;\n' +
         '&lt;/tr&gt;\n' +
-        '\n' +
         '                    &lt;/tbody&gt;\n' +
         '                &lt;/table&gt;\n' +
         '            &lt;/div&gt;\n' +

From f3cadb96677d0eb82fc2752dc3ffbf35ca9b5bdb Mon Sep 17 00:00:00 2001
From: Rodrigo Fernandes &lt;rtfrodrigo@gmail.com&gt;
Date: Sat, 15 Oct 2016 13:21:22 +0100
Subject: [PATCH 2/2] Allow uncompiled templates

---
 README.md                 |  3 +++
 src/hoganjs-utils.js      |  7 +++++++
 test/hogan-cache-tests.js | 24 +++++++++++++++++++++++-
 3 files changed, 33 insertions(+), 1 deletion(-)

diff --git a/README.md b/README.md
index 132c8a28..46909f25 100644
--- a/README.md
+++ b/README.md
@@ -98,6 +98,9 @@ The HTML output accepts a Javascript object with configuration. Possible options
   - `synchronisedScroll`: scroll both panes in side-by-side mode: `true` or `false`, default is `false`
   - `matchWordsThreshold`: similarity threshold for word matching, default is 0.25
   - `matchingMaxComparisons`: perform at most this much comparisons for line matching a block of changes, default is `2500`
+  - `templates`: object with previously compiled templates to replace parts of the html
+  - `rawTemplates`: object with raw not compiled templates to replace parts of the html
+  &gt; For more information regarding the possible templates look into [src/templates](https://github.com/rtfpessoa/diff2html/tree/master/src/templates)

 ## Diff2HtmlUI Helper

diff --git a/src/hoganjs-utils.js b/src/hoganjs-utils.js
index 0dda08d7..b2e9c275 100644
--- a/src/hoganjs-utils.js
+++ b/src/hoganjs-utils.js
@@ -17,6 +17,13 @@
   function HoganJsUtils(configuration) {
     this.config = configuration || {};
     extraTemplates = this.config.templates || {};
+
+    var rawTemplates = this.config.rawTemplates || {};
+    for (var templateName in rawTemplates) {
+      if (rawTemplates.hasOwnProperty(templateName)) {
+        if (!extraTemplates[templateName]) extraTemplates[templateName] = this.compile(rawTemplates[templateName]);
+      }
+    }
   }

   HoganJsUtils.prototype.render = function(namespace, view, params) {
diff --git a/test/hogan-cache-tests.js b/test/hogan-cache-tests.js
index 3bb754ac..a34839c0 100644
--- a/test/hogan-cache-tests.js
+++ b/test/hogan-cache-tests.js
@@ -36,7 +36,7 @@ describe('HoganJsUtils', function() {
       assert.equal(null, result);
     });

-    it('should allow templates to be overridden', function() {
+    it('should allow templates to be overridden with compiled templates', function() {
       var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');

       var config = {templates: {'generic-empty-diff': emptyDiffTemplate}};
@@ -44,5 +44,27 @@ describe('HoganJsUtils', function() {
       var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
       assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
     });
+
+    it('should allow templates to be overridden with uncompiled templates', function() {
+      var emptyDiffTemplate = '&lt;p&gt;&lt;/p&gt;';
+
+      var config = {rawTemplates: {'generic-empty-diff': emptyDiffTemplate}};
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
+
+    it('should allow templates to be overridden giving priority to compiled templates', function() {
+      var emptyDiffTemplate = HoganJsUtils.compile('&lt;p&gt;&lt;/p&gt;');
+      var emptyDiffTemplateUncompiled = '&lt;p&gt;Not used!&lt;/p&gt;';
+
+      var config = {
+        templates: {'generic-empty-diff': emptyDiffTemplate},
+        rawTemplates: {'generic-empty-diff': emptyDiffTemplateUncompiled}
+      };
+      var hoganUtils = new (require('../src/hoganjs-utils.js').HoganJsUtils)(config);
+      var result = hoganUtils.render('generic', 'empty-diff', {myName: 'Rodrigo Fernandes'});
+      assert.equal('&lt;p&gt;Rodrigo Fernandes&lt;/p&gt;', result);
+    });
   });
 });
</code></pre>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="code"/><summary type="html"><![CDATA[this is how you can display code diffs]]></summary></entry><entry><title type="html">a post with advanced image components</title><link href="https://nayoung10.github.io/blog/2024/advanced-images/" rel="alternate" type="text/html" title="a post with advanced image components"/><published>2024-01-27T11:46:00+00:00</published><updated>2024-01-27T11:46:00+00:00</updated><id>https://nayoung10.github.io/blog/2024/advanced-images</id><content type="html" xml:base="https://nayoung10.github.io/blog/2024/advanced-images/"><![CDATA[<p>This is an example post with advanced image components.</p> <h2 id="image-slider">Image Slider</h2> <p>This is a simple image slider. It uses the <a href="https://swiperjs.com/">Swiper</a> library. Check the <a href="https://swiperjs.com/demos">examples page</a> for more information of what you can achieve with it.</p> <swiper-container keyboard="true" navigation="true" pagination="true" pagination-clickable="true" pagination-dynamic-bullets="true" rewind="true"> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/9-480.webp 480w,/assets/img/9-800.webp 800w,/assets/img/9-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/9.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/7-480.webp 480w,/assets/img/7-800.webp 800w,/assets/img/7-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/7.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/8-480.webp 480w,/assets/img/8-800.webp 800w,/assets/img/8-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/8.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/10-480.webp 480w,/assets/img/10-800.webp 800w,/assets/img/10-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/10.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> <swiper-slide> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/12-480.webp 480w,/assets/img/12-800.webp 800w,/assets/img/12-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/12.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </swiper-slide> </swiper-container> <h2 id="image-comparison-slider">Image Comparison Slider</h2> <p>This is a simple image comparison slider. It uses the <a href="https://img-comparison-slider.sneas.io/">img-comparison-slider</a> library. Check the <a href="https://img-comparison-slider.sneas.io/examples.html">examples page</a> for more information of what you can achieve with it.</p> <img-comparison-slider> <figure slot="first"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic-480.webp 480w,/assets/img/prof_pic-800.webp 800w,/assets/img/prof_pic-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/prof_pic.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> <figure slot="second"> <picture> <source class="responsive-img-srcset" srcset="/assets/img/prof_pic_color-480.webp 480w,/assets/img/prof_pic_color-800.webp 800w,/assets/img/prof_pic_color-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="/assets/img/prof_pic_color.png" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="lazy" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"/> </picture> </figure> </img-comparison-slider>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="images"/><summary type="html"><![CDATA[this is what advanced image components could look like]]></summary></entry><entry><title type="html">a post with vega lite</title><link href="https://nayoung10.github.io/blog/2024/vega-lite/" rel="alternate" type="text/html" title="a post with vega lite"/><published>2024-01-27T00:20:00+00:00</published><updated>2024-01-27T00:20:00+00:00</updated><id>https://nayoung10.github.io/blog/2024/vega-lite</id><content type="html" xml:base="https://nayoung10.github.io/blog/2024/vega-lite/"><![CDATA[<p>This is an example post with some <a href="https://vega.github.io/vega-lite/">vega lite</a> code.</p> <div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="p">```</span><span class="nl">vega_lite
</span><span class="sb">{
  "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
  "description": "A dot plot showing each movie in the database, and the difference from the average movie rating. The display is sorted by year to visualize everything in sequential order. The graph is for all Movies before 2019.",
  "data": {
    "url": "https://raw.githubusercontent.com/vega/vega/main/docs/data/movies.json"
  },
  "transform": [
    {"filter": "datum['IMDB Rating'] != null"},
    {"filter": {"timeUnit": "year", "field": "Release Date", "range": [null, 2019]}},
    {
      "joinaggregate": [{
        "op": "mean",
        "field": "IMDB Rating",
        "as": "AverageRating"
      }]
    },
    {
      "calculate": "datum['IMDB Rating'] - datum.AverageRating",
      "as": "RatingDelta"
    }
  ],
  "mark": "point",
  "encoding": {
    "x": {
      "field": "Release Date",
      "type": "temporal"
    },
    "y": {
      "field": "RatingDelta",
      "type": "quantitative",
      "title": "Rating Delta"
    },
    "color": {
      "field": "RatingDelta",
      "type": "quantitative",
      "scale": {"domainMid": 0},
      "title": "Rating Delta"
    }
  }
}</span>
<span class="p">```</span>
</code></pre></div></div> <p>Which generates:</p> <pre><code class="language-vega_lite">{
  "$schema": "https://vega.github.io/schema/vega-lite/v5.json",
  "description": "A dot plot showing each movie in the database, and the difference from the average movie rating. The display is sorted by year to visualize everything in sequential order. The graph is for all Movies before 2019.",
  "data": {
    "url": "https://raw.githubusercontent.com/vega/vega/main/docs/data/movies.json"
  },
  "transform": [
    {"filter": "datum['IMDB Rating'] != null"},
    {"filter": {"timeUnit": "year", "field": "Release Date", "range": [null, 2019]}},
    {
      "joinaggregate": [{
        "op": "mean",
        "field": "IMDB Rating",
        "as": "AverageRating"
      }]
    },
    {
      "calculate": "datum['IMDB Rating'] - datum.AverageRating",
      "as": "RatingDelta"
    }
  ],
  "mark": "point",
  "encoding": {
    "x": {
      "field": "Release Date",
      "type": "temporal"
    },
    "y": {
      "field": "RatingDelta",
      "type": "quantitative",
      "title": "Rating Delta"
    },
    "color": {
      "field": "RatingDelta",
      "type": "quantitative",
      "scale": {"domainMid": 0},
      "title": "Rating Delta"
    }
  }
}
</code></pre> <p>This plot supports both light and dark themes.</p>]]></content><author><name></name></author><category term="sample-posts"/><category term="formatting"/><category term="charts"/><summary type="html"><![CDATA[this is what included vega lite code could look like]]></summary></entry></feed>